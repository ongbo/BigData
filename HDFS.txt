-----------------------------------------------------------HDFS----------------------------------------------------
------------------------------------分布式文件系统：：：：：：：硬盘存储
设计思想：分而治之       
		分：切分存储，当一个文件过大的时候，就采用切分存储
			1）分块存储：每一个块叫做block
			2）分块大小：假如一个数据8T，设计分块时要考虑负载均衡，块的大小不能太大，hadoop2.x中默认切分大小是128M，hadoop1.x默认64M
			3）块怎么存：每个块可能存在不同电脑上，如果一个文件不足128M,也会单独存一个块，不会把两个块拼接在一起。
			4）数据安全：备份思想，hdfs中默认备份机制是3份，可以自己配置dfs.replication，所有备份是相同地位，没有主次之分。备份的数据块存在不同			节点上。
						如果节点中总共2个，副本是3个，实际存储2个，因为相同的数据块存储在同一节点没有意义，另外一个进行记账，当集群节点个数大于等于3时候就会复制这个副本。
						如果节点4个，副本3个，有一个副本宕机了，这个时候发现副本个数小于设定个数，就会进行复制，达到3个副本，如果宕机的节点又恢复了，集群会等待一段时间，如果发现还是4个就会随机删除一个副本。
						全新集群分配方式？：
						旧集群分配方式？：
		副本越多，数据安全性越高，但是副本数越多，硬盘存储-----资源浪费，会造成副本维护成本过高。维护变得越困难，如果有100个节点副本50个，hdfs需要同时维护50个副本，这50个副本中随时都有可能发生宕机，就要去维护，一天到晚都在维护
		hadoop是基于 廉价的pc机
  	影响负载均衡的原因：负载均衡就是各个节点承担的数据压力和计算压力是否均衡，和各个节点的配置有关
  		1：块的大小    2：所有块的副本是否分配均匀到节点上，均匀和硬件配置有关

-----------------------------------hdfs整体架构：
主从架构
一个主节点  多个从节点
	namenode：
			1：用于存储元数据
				元数据包括：1）抽象目录树
				hdfs的目录结构和Linux文件系统相似， 以/为根节点  其目录结构代表所有数据节点抽象出来的目录，不代表任何一个节点。 
						   2）存储数据和block的对应关系 hdfs中存储的数据块是有编号的，比如blk_1,blk_2...底层存储时每一个block都有一个唯一的id
						   3）记录block存储的位置，hdfs的底层数据存储的时候还是存储在真实物理机上
			2：用于处理客户端的读写请求  读--下载    写---上传
	datanode ：
			1：负责真正的数据存储，存储数据的block
			2：真正的处理读写
	secondarynamenode ：冷备份节点：助理
			1）当namenode宕机的时候，secondarynamenode不能主动切换为namenode，但是它存储的数据和namenode相同
			主要作用是当namenode宕机的时候，帮助namenode恢复 
			2）帮助namenode做一些事情（元数据合并），分担namenode压力


------------------------------------hdfs优缺点
优点：
	可构建在廉价机器上，成本低
	通过多副本提高可靠性，提供了容错和恢复机制
	高容错性：数据访问上，一个数据丢失不影响整体数据访问，数据自动保存多个副本，副本丢失自动恢复
	适合批处理，离线数据处理：移动计算而非数据，数据位置,
	适合大数据出出力
	流式文件访问：不支持数据修改，一次性写入（不然一旦修改，所有的都要改），保持数据一致性
缺点：
    1：不支持低延迟数据访问：
    	低延迟：要求访问数据立即返回
    2：不擅长存储大量的小文件，kb级别（寻址时间太长，进行数据访问的时候先找元数据，元数据是与block对应的，如果存储1000万个1kb数据就有1000万个块，可能会要很长时间找数据块的位置，效率太低，而读取数据可能就1ms）。会造成元数据存储量过大，增加了namenode的压力，在hdfs中，一条元数据大概150字节左右。
    3：不支持文件内容修改

---------------------------------hdfs  API
FileSystem：这个独享是hdfs目录树的一个实例，如果用户想要操作hdfs必须获取这个实例
		实例获取：new
				反射
				工厂类
				单例设计模式，静态方法
				克隆
Configuration：加载配置文件对象，搭建hadoop集群时候，通过配置文件建立起来,
				
	Configuration conf=new Configuration();
		//代码上传的的文件备份配置是读的jar包中hadoop_home/share/hadoop/hdfs/hdfs-...jar，而集群中读的是自己配置的
		加载配置文件的顺序：1：jar包中的hdfs-default.xml
							2：工程的classpath中src的配置文件,只能识别两种hdfs-default.xml,hdfs-site.xml
							3：conf.set("");//也可以通过配置文件设置配置文件
						但是后面的会把前面的配置覆盖掉	
						
	FileSystem fs=FileSystem.get(conf);//获取本地文件系统
	FileSystem fs=FileSystem.get(uri,conf);//uri=new URI("hdfs://hadoop01:9000"),这个就是获取的hdfs分布式文件系统（抽象目录树）
		hdfs全路径：hdfs://hadoop01:9000/
		本地文件系统：file\\\D(C)啥的


------------------------------------hdfs四大机制，两大核心
hdfs提供高容错性的分布式的数据存储方案，依赖于四大机制和两大核心
hadoop集群启动顺秀：namenode    datanode    secondarynamenode
四大机制：

	心跳机制：
		集群之间必须做时间同步
		namenode是集群老大，负责集群上任务分工，如果要进行任务分工，必须知道各个从节点的存活状况。
		通过datanode定期向namenode发送心跳报告确定的，datanode每3秒（dfs.hearbeat.interval配置）向namenode发送一次心跳报告，目的是告诉
		namenode自己的存活状况。
		namenode什么时候判断datanode死了？：当namenode连续十次没有收到datanode的心跳报告，就认为datanode可能死了，并没有断定它死掉，这个时候
		namenode会主动向datanode发送一次检查，发送一次检查的时间是5分钟（dfs.namenode.hearbeat.recheck-interval配置），如果一次检查没有返回信息，这个时候会再一次进行检查，如果还获取不到则会认为他死了。10*3s+2*5min=630s，连续630s没有得到datanode消息就认为datanode死了。


    安全模式
	    元数据：
		1）抽象目录树
		2）数据和块的映射关系
		3）数据块存储的位置信息
		元数据存储的位置是：		
		磁盘：元数据如果存储在磁盘，那么每次进行文件读写的时候，都会进行磁盘读写，磁盘IO是所有计算机的读写的瓶颈，必然造成性能降低。抽象目录树，数据和块的映射关系
		内存：读写快，但是一旦关机就会造成数据丢失，内存只存两个部分：抽象目录树，数据和块的映射关系，数据块存储的位置信息
		所以元数据内存和磁盘中都有。

    	集群启动时namenode需要做哪些事情：
    		1）首先将磁盘元数据加载到内存中，如果磁盘元数据过大，会造成加载到内存时间过长，所以磁盘中的数据只存储了1,2部分，
    		2）datanode启动后，namenode就收datanode的心跳报告：获取存活状况，namenode元数据的数据块存储的位置信息是通过datanode的心跳报告获取的，集群在启动的时候会接收datanode的心跳报告，这个心跳报告中还包含数据块的存储位置信息，这时候namenode就可以获取datanode的数据块存储状况。
    		3)启动secondarynamenode
    	集群在执行这个过程的时候不允许外界对集群进行操作，这时候集群处于安全模式
    	也就是说集群处于安全模式的时候在加载和获取datanode的心跳报告
    	如果集群处于维护或者升级的时候也可以手动将集群设置为安全模式：hdfs dfsadmin -safemode enter（leave）:进入（离开）安全模式
	
    	安全模式下用户可以执行的操作： 不修改元数据的操作都可以
    				ls查询
    				cat查看文件内容
    				下载-get可以

    				不可以创建目录	不可以上传文件 修改文件命名  追加文件都不可以
	机架策略：副本存放机制  默认情况下每个数据块有3个副本
		副本存放策略：第一个副本一般存储在客户端所在的节点上
					第二个节点存储在和第一个不同机架上的任意一个节点上，防止断电数据丢失
					第三个副本存储在和第一个副本相同机架上的不同节点上，减少网络传输。
			真实生产中需要制定机架策略。
			真实生产中可以自定义：不同节点，不同机架，不同数据中心。

	负载均衡：
		什么是负载均衡：每个节点数据存储的百分比相差不大。
		能力越大，责任越大。

		文件进行上传的时候会优先选择客户端所在节点，如果习惯使用同一个客户端会造成客户端所在节点存储的数据比较多
		集群会有一个自动的负载均衡的操作，但是比较慢。默认情况下集群在进行自动负载均衡的时候的带宽默认最大是1M，集群在进行自动负载均衡的时候是很慢
		对于小规模的集群节点，是可以使用自动负载均衡
		大规模集群，需要手动控制。start-balancer.sh,但是这个命令也不一定执行，会等到hadoop集群空闲的时候才会执行
		但是不存在绝对的均衡，
		start-balancer.sh -t 10%指的是任意两个节点之间的存储百分比不超过10%则认为到达负载均衡

核心：
		上传	：
			1：客户端向namenode发送文件上传请求，包含数据长度信息
			2：namonode检查这个文件是否存在
			  上传文件的父母录是否存在，不存在报错
		      检查权限等等
			3：检查通过，向客户端返回存储检点信息
				优先返回客户端所在节点
				返回同机架的节点
				返回不同机架的节点
			4：客户端接收namenode返回响应后，会进行一次逻辑切分（并没有真正切分，仅仅做一个切分规划）
			5：开始准备文件上传。
			6：构建pipeline通道，根据块id一次进行构建，将同一块的所有存储节点构建成一个数据流通道
				blk_1:客户端->hadoop01->hadoop02->hadoop03构建通道成功->hadoop02->hadoop01->客户端
			7：进行文件上传。上传过程中，边进行上传边进行切分，上传是一package为单位进行上传，一个package是512M。上传过程中,先上传到datanode01中，会先写到缓存中，没接收到一个package就可以往下一个节点传递，同时缓存中的数据还会向磁盘中写。     
			8：当第一个块数据上传完成后关闭通道
			9：重复6，7,8
			10：所有块上传完成后，会告诉客户端返回结果，数据上传成功。
			11：客户端告诉namenode返回信息，告知数据上传成功，namenode检查，如果成功，就要更新元数据

		下载：
			1)客户端向namenode发送文件下载的请求
			2）namenode也会进行一系列的检查 
				文件是否存在，是否有权限等
				如果这一系列的检查没有问题，这个时候开始查询自己的元数据库
				返回数据对应的块以及块的存储位置给客户端 
			3）客户端拿到数据快的存储信息，开始进行第一个块的下载 
				从哪一个节点下载？就近原则，优先选择客户端所在的节点》》》同机架》》》不同机架
				如果块下载失败怎么办？会再进行尝试一次， 如果还失败客户端会将这个失败的节点返回给namenode 同时会继续从另外的节点进行下载这个块。
			4）第一个块下载完成之后，会进行crc校验，如果校验通过 则认为下载成功。
			5）开始进行第二个块的下载，重复步骤4，进行文件追加
			6）当所有的数据块下载成功之后，客户端向namenode反馈




---------------------------------------元数据
hadoop/data/hadoopdata:
	data:数据的真实存储目录，datanode存储数据的存储目录
	name：namenode存储元数据的目录
	nm-local-dir:本地缓存 hdfs的本地缓存

	元数据存储目录下的文件分为四类：
		1：历史日志文件
			记录客户端对元数据操作的日志，只记录操作信息，比如某一个用户对某一目录执行某一个操作。
		2：正在编辑的日志文件
			正在对元数据修改的操作
		3：镜像文件
			真实的元数据进行序列化后的文件（经过序列化是为了加快加载，加载就进行反序列化）
		4：合并点记录文件，记录的是下一次合并的日志文件
	真实硬盘上存储的元数据：fsimage+正在编辑的日志文件

元数据合并过程
	


